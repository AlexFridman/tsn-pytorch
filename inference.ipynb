{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T16:04:01.595538Z",
     "start_time": "2017-09-12T16:04:01.587707Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "\n",
    "from dataset import TSNDataSet\n",
    "from models import TSN\n",
    "from opts import parser\n",
    "from transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T15:40:46.529409Z",
     "start_time": "2017-09-12T15:40:46.524355Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args_str = \"\"\"ucf101 RGB \\\n",
    "    /media/e/vsd/data/ucf101_preprocessed/split_01/file_lists/train_rgb.txt \\\n",
    "    /media/e/vsd/data/ucf101_preprocessed/split_01/file_lists/test_rgb.txt \\\n",
    "    --arch BNInception --num_segments 3 \\\n",
    "    --gd 20 --lr 0.001 --lr_steps 30 60 --epochs 80 \\\n",
    "    -b 32 -j 4 \\\n",
    "    --snapshot_pref ucf101_bninception_\"\"\"\n",
    "\n",
    "args = parser.parse_args(args_str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T15:40:46.759885Z",
     "start_time": "2017-09-12T15:40:46.712144Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arch = 'BNInception'\n",
    "batch_size = 4\n",
    "clip_gradient = 20.0\n",
    "consensus_type = 'avg'\n",
    "dataset = 'ucf101'\n",
    "dropout = 0.5\n",
    "epochs = 80\n",
    "eval_freq = 5\n",
    "evaluate = False\n",
    "flow_prefix = ''\n",
    "gpus = None\n",
    "k = 3\n",
    "loss_type = 'nll'\n",
    "lr = 0.001\n",
    "lr_steps = [30.0, 60.0]\n",
    "modality = 'RGB'\n",
    "momentum = 0.9\n",
    "no_partialbn = False\n",
    "num_segments = 3\n",
    "print_freq = 10\n",
    "resume = False\n",
    "snapshot_pref = 'ucf101_bninception_'\n",
    "start_epoch = 0\n",
    "train_list = '/media/e/vsd/data/ucf101_preprocessed/split_01/file_lists/train_rgb.txt'\n",
    "val_list = '/media/e/vsd/data/ucf101_preprocessed/split_01/file_lists/test_rgb.txt'\n",
    "weight_decay = 0.0005\n",
    "workers = 4\n",
    "\n",
    "num_class = 108\n",
    "\n",
    "checkpoint_path = '/media/d/vsd/tsn-pytorch/ucf101_bninception__rgb_model_best.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T15:40:48.427477Z",
     "start_time": "2017-09-12T15:40:46.984369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing TSN with base model: BNInception.\n",
      "TSN Configurations:\n",
      "    input_modality:     RGB\n",
      "    num_segments:       3\n",
      "    new_length:         1\n",
      "    consensus_module:   avg\n",
      "    dropout_ratio:      0.5\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py:360: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  own_state[name].copy_(param)\n"
     ]
    }
   ],
   "source": [
    "model = TSN(num_class, num_segments, modality,\n",
    "                base_model=arch,\n",
    "                consensus_type=consensus_type, dropout=dropout, partial_bn=not no_partialbn)\n",
    "\n",
    "crop_size = model.crop_size\n",
    "scale_size = model.scale_size\n",
    "input_mean = model.input_mean\n",
    "input_std = model.input_std\n",
    "policies = model.get_optim_policies()\n",
    "train_augmentation = model.get_augmentation()\n",
    "\n",
    "model = torch.nn.DataParallel(model, device_ids=gpus).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T15:40:48.458993Z",
     "start_time": "2017-09-12T15:40:48.428390Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T15:40:49.218499Z",
     "start_time": "2017-09-12T15:40:49.213055Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if args.modality != 'RGBDiff':\n",
    "#     normalize = GroupNormalize(input_mean, input_std)\n",
    "# else:\n",
    "#     normalize = IdentityTransform()\n",
    "\n",
    "# if args.modality == 'RGB':\n",
    "#     data_length = 1\n",
    "# elif args.modality in ['Flow', 'RGBDiff']:\n",
    "#     data_length = 5\n",
    "\n",
    "data_length = 1\n",
    "data_length = 5\n",
    "\n",
    "normalize = IdentityTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T15:58:34.412069Z",
     "start_time": "2017-09-12T15:58:34.402807Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "                   GroupScale(int(scale_size)),\n",
    "                   GroupCenterCrop(crop_size),\n",
    "                   Stack(roll=arch == 'BNInception'),\n",
    "                   ToTorchFormatTensor(div=arch != 'BNInception'),\n",
    "                   normalize,\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T15:58:50.548734Z",
     "start_time": "2017-09-12T15:58:50.543309Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     TSNDataSet(\"\", val_list, num_segments=num_segments,\n",
    "#                new_length=data_length,\n",
    "#                modality=modality,\n",
    "#                image_tmpl=\"{:04d}.jpg\" if modality in ['RGB', 'RGBDiff'] else \"{:04d}.flo\",\n",
    "#                random_shift=False,\n",
    "#                transform=torchvision.transforms.Compose([\n",
    "#                    GroupScale(int(scale_size)),\n",
    "#                    GroupCenterCrop(crop_size),\n",
    "#                    Stack(roll=arch == 'BNInception'),\n",
    "#                    ToTorchFormatTensor(div=arch != 'BNInception'),\n",
    "#                    normalize,\n",
    "#                ])),\n",
    "#     batch_size=1, shuffle=False,\n",
    "#     num_workers=workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T15:41:21.634339Z",
     "start_time": "2017-09-12T15:41:21.623267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing BatchNorm2D except the first one.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel (\n",
       "  (module): TSN (\n",
       "    (base_model): BNInception (\n",
       "      (conv1_7x7_s2): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv1_relu_7x7): ReLU (inplace)\n",
       "      (pool1_3x3_s2): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "      (conv2_3x3_reduce): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2_relu_3x3_reduce): ReLU (inplace)\n",
       "      (conv2_3x3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2_relu_3x3): ReLU (inplace)\n",
       "      (pool2_3x3_s2): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "      (inception_3a_1x1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3a_relu_1x1): ReLU (inplace)\n",
       "      (inception_3a_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3a_relu_3x3_reduce): ReLU (inplace)\n",
       "      (inception_3a_3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3a_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3a_relu_3x3): ReLU (inplace)\n",
       "      (inception_3a_double_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3a_relu_double_3x3_reduce): ReLU (inplace)\n",
       "      (inception_3a_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3a_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3a_relu_double_3x3_1): ReLU (inplace)\n",
       "      (inception_3a_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3a_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3a_relu_double_3x3_2): ReLU (inplace)\n",
       "      (inception_3a_pool): AvgPool2d (size=3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
       "      (inception_3a_pool_proj): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_pool_proj_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3a_relu_pool_proj): ReLU (inplace)\n",
       "      (inception_3b_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3b_relu_1x1): ReLU (inplace)\n",
       "      (inception_3b_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3b_relu_3x3_reduce): ReLU (inplace)\n",
       "      (inception_3b_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3b_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3b_relu_3x3): ReLU (inplace)\n",
       "      (inception_3b_double_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3b_relu_double_3x3_reduce): ReLU (inplace)\n",
       "      (inception_3b_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3b_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3b_relu_double_3x3_1): ReLU (inplace)\n",
       "      (inception_3b_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3b_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3b_relu_double_3x3_2): ReLU (inplace)\n",
       "      (inception_3b_pool): AvgPool2d (size=3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
       "      (inception_3b_pool_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_pool_proj_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3b_relu_pool_proj): ReLU (inplace)\n",
       "      (inception_3c_3x3_reduce): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3c_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3c_relu_3x3_reduce): ReLU (inplace)\n",
       "      (inception_3c_3x3): Conv2d(128, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (inception_3c_3x3_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3c_relu_3x3): ReLU (inplace)\n",
       "      (inception_3c_double_3x3_reduce): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3c_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3c_relu_double_3x3_reduce): ReLU (inplace)\n",
       "      (inception_3c_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3c_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3c_relu_double_3x3_1): ReLU (inplace)\n",
       "      (inception_3c_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (inception_3c_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_3c_relu_double_3x3_2): ReLU (inplace)\n",
       "      (inception_3c_pool): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "      (inception_4a_1x1): Conv2d(576, 224, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4a_1x1_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4a_relu_1x1): ReLU (inplace)\n",
       "      (inception_4a_3x3_reduce): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4a_relu_3x3_reduce): ReLU (inplace)\n",
       "      (inception_4a_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_4a_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4a_relu_3x3): ReLU (inplace)\n",
       "      (inception_4a_double_3x3_reduce): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4a_double_3x3_reduce_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4a_relu_double_3x3_reduce): ReLU (inplace)\n",
       "      (inception_4a_double_3x3_1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_4a_double_3x3_1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4a_relu_double_3x3_1): ReLU (inplace)\n",
       "      (inception_4a_double_3x3_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_4a_double_3x3_2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4a_relu_double_3x3_2): ReLU (inplace)\n",
       "      (inception_4a_pool): AvgPool2d (size=3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
       "      (inception_4a_pool_proj): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4a_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4a_relu_pool_proj): ReLU (inplace)\n",
       "      (inception_4b_1x1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4b_1x1_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4b_relu_1x1): ReLU (inplace)\n",
       "      (inception_4b_3x3_reduce): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4b_3x3_reduce_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4b_relu_3x3_reduce): ReLU (inplace)\n",
       "      (inception_4b_3x3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_4b_3x3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4b_relu_3x3): ReLU (inplace)\n",
       "      (inception_4b_double_3x3_reduce): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4b_double_3x3_reduce_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4b_relu_double_3x3_reduce): ReLU (inplace)\n",
       "      (inception_4b_double_3x3_1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_4b_double_3x3_1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4b_relu_double_3x3_1): ReLU (inplace)\n",
       "      (inception_4b_double_3x3_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_4b_double_3x3_2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4b_relu_double_3x3_2): ReLU (inplace)\n",
       "      (inception_4b_pool): AvgPool2d (size=3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
       "      (inception_4b_pool_proj): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4b_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4b_relu_pool_proj): ReLU (inplace)\n",
       "      (inception_4c_1x1): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4c_1x1_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4c_relu_1x1): ReLU (inplace)\n",
       "      (inception_4c_3x3_reduce): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4c_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4c_relu_3x3_reduce): ReLU (inplace)\n",
       "      (inception_4c_3x3): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_4c_3x3_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4c_relu_3x3): ReLU (inplace)\n",
       "      (inception_4c_double_3x3_reduce): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4c_double_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4c_relu_double_3x3_reduce): ReLU (inplace)\n",
       "      (inception_4c_double_3x3_1): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_4c_double_3x3_1_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4c_relu_double_3x3_1): ReLU (inplace)\n",
       "      (inception_4c_double_3x3_2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_4c_double_3x3_2_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4c_relu_double_3x3_2): ReLU (inplace)\n",
       "      (inception_4c_pool): AvgPool2d (size=3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
       "      (inception_4c_pool_proj): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4c_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4c_relu_pool_proj): ReLU (inplace)\n",
       "      (inception_4d_1x1): Conv2d(608, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4d_1x1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4d_relu_1x1): ReLU (inplace)\n",
       "      (inception_4d_3x3_reduce): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4d_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4d_relu_3x3_reduce): ReLU (inplace)\n",
       "      (inception_4d_3x3): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_4d_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4d_relu_3x3): ReLU (inplace)\n",
       "      (inception_4d_double_3x3_reduce): Conv2d(608, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4d_double_3x3_reduce_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4d_relu_double_3x3_reduce): ReLU (inplace)\n",
       "      (inception_4d_double_3x3_1): Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_4d_double_3x3_1_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4d_relu_double_3x3_1): ReLU (inplace)\n",
       "      (inception_4d_double_3x3_2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_4d_double_3x3_2_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4d_relu_double_3x3_2): ReLU (inplace)\n",
       "      (inception_4d_pool): AvgPool2d (size=3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
       "      (inception_4d_pool_proj): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4d_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4d_relu_pool_proj): ReLU (inplace)\n",
       "      (inception_4e_3x3_reduce): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4e_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4e_relu_3x3_reduce): ReLU (inplace)\n",
       "      (inception_4e_3x3): Conv2d(128, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (inception_4e_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4e_relu_3x3): ReLU (inplace)\n",
       "      (inception_4e_double_3x3_reduce): Conv2d(608, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_4e_double_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4e_relu_double_3x3_reduce): ReLU (inplace)\n",
       "      (inception_4e_double_3x3_1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_4e_double_3x3_1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4e_relu_double_3x3_1): ReLU (inplace)\n",
       "      (inception_4e_double_3x3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (inception_4e_double_3x3_2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_4e_relu_double_3x3_2): ReLU (inplace)\n",
       "      (inception_4e_pool): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "      (inception_5a_1x1): Conv2d(1056, 352, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_5a_1x1_bn): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5a_relu_1x1): ReLU (inplace)\n",
       "      (inception_5a_3x3_reduce): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_5a_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5a_relu_3x3_reduce): ReLU (inplace)\n",
       "      (inception_5a_3x3): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_5a_3x3_bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5a_relu_3x3): ReLU (inplace)\n",
       "      (inception_5a_double_3x3_reduce): Conv2d(1056, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_5a_double_3x3_reduce_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5a_relu_double_3x3_reduce): ReLU (inplace)\n",
       "      (inception_5a_double_3x3_1): Conv2d(160, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_5a_double_3x3_1_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5a_relu_double_3x3_1): ReLU (inplace)\n",
       "      (inception_5a_double_3x3_2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_5a_double_3x3_2_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5a_relu_double_3x3_2): ReLU (inplace)\n",
       "      (inception_5a_pool): AvgPool2d (size=3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
       "      (inception_5a_pool_proj): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_5a_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5a_relu_pool_proj): ReLU (inplace)\n",
       "      (inception_5b_1x1): Conv2d(1024, 352, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_5b_1x1_bn): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5b_relu_1x1): ReLU (inplace)\n",
       "      (inception_5b_3x3_reduce): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_5b_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5b_relu_3x3_reduce): ReLU (inplace)\n",
       "      (inception_5b_3x3): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_5b_3x3_bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5b_relu_3x3): ReLU (inplace)\n",
       "      (inception_5b_double_3x3_reduce): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_5b_double_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5b_relu_double_3x3_reduce): ReLU (inplace)\n",
       "      (inception_5b_double_3x3_1): Conv2d(192, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_5b_double_3x3_1_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5b_relu_double_3x3_1): ReLU (inplace)\n",
       "      (inception_5b_double_3x3_2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_5b_double_3x3_2_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5b_relu_double_3x3_2): ReLU (inplace)\n",
       "      (inception_5b_pool): MaxPool2d (size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1))\n",
       "      (inception_5b_pool_proj): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_5b_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (inception_5b_relu_pool_proj): ReLU (inplace)\n",
       "      (global_pool): AvgPool2d (size=7, stride=1, padding=0, ceil_mode=True, count_include_pad=True)\n",
       "      (fc): Dropout (p = 0.5)\n",
       "    )\n",
       "    (new_fc): Linear (1024 -> 108)\n",
       "    (consensus): ConsensusModule (\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T15:38:32.616865Z",
     "start_time": "2017-09-12T15:38:32.613360Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T17:05:33.367585Z",
     "start_time": "2017-09-12T17:05:33.363312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 3, 4]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [1, 2, 3, 4]\n",
    "c + c[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T17:08:25.504721Z",
     "start_time": "2017-09-12T17:08:25.463035Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEGMENT_TIME = 3\n",
    "SEQ_LENGTH = 25\n",
    "FPS = 25\n",
    "\n",
    "def split_frames(frames):\n",
    "    def chunks(l, n):\n",
    "        \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "        for i in range(0, len(l), n):\n",
    "            yield l[i:i + n]\n",
    "\n",
    "    n_frames = len(frames)\n",
    "    segment_length = FPS * SEGMENT_TIME\n",
    "\n",
    "    for i, chunk in enumerate(chunks(frames, segment_length)):\n",
    "        if len(chunk) != segment_length:\n",
    "            times = segment_length // len(chunk)\n",
    "            yield (chunk * times + chunk[:len(chunk) - segment_length * times],\n",
    "                   i * SEGMENT_TIME, (i + 1) * SEGMENT_TIME)\n",
    "        else:\n",
    "            yield chunk, i * SEGMENT_TIME, (i + 1) * SEGMENT_TIME\n",
    "        \n",
    "        \n",
    "def get_rgb_frames(rgb_frames_path):\n",
    "    import glob\n",
    "    \n",
    "    return list(sorted(glob.glob(rgb_frames_path + '/' + '*jpg')))\n",
    "\n",
    "def load_segment(frames):\n",
    "    return [Image.open(frame).convert('RGB') for frame in frames]\n",
    "\n",
    "def make_prediction_on_segment(segment):\n",
    "    images = load_segment(segment)\n",
    "    images = transform(images)\n",
    "    images = images.unsqueeze(0)\n",
    "    \n",
    "    input_var = torch.autograd.Variable(images, volatile=True)\n",
    "    \n",
    "    output = model(input_var)\n",
    "    \n",
    "    _, pred = output.mean(dim=0).topk(5)\n",
    "    return pred.cpu().data.numpy()\n",
    "\n",
    "def build_class_index():\n",
    "    return {i: class_ for i, class_ in enumerate(sorted(os.listdir('/media/d/vsd/data/ucf101/UCF-101/')))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T17:08:25.730109Z",
     "start_time": "2017-09-12T17:08:25.725122Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_index = build_class_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T17:08:26.002882Z",
     "start_time": "2017-09-12T17:08:25.993818Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rgb_frames_path = '/media/d/vsd/data/imitations_temp/rgb/IMG_0085/'\n",
    "frames = get_rgb_frames(rgb_frames_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T17:08:39.418948Z",
     "start_time": "2017-09-12T17:08:26.383321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa52d5d338e4dc1b4927e4d9cbe7169"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 225, 224, 224])\n",
      "torch.Size([1, 225, 224, 224])\n",
      "\n",
      "torch.Size([1, 225, 224, 224])\n",
      "torch.Size([1, 225, 224, 224])\n",
      "torch.Size([1, 225, 224, 224])\n",
      "torch.Size([1, 225, 224, 224])\n",
      "torch.Size([1, 414, 224, 224])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "preds = {}\n",
    "\n",
    "for segment, start_time, end_time in tqdm_notebook(split_frames(frames)):\n",
    "    preds[(start_time, end_time)] = [class_index[int(class_id)] for class_id in make_prediction_on_segment(segment)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T17:08:39.422517Z",
     "start_time": "2017-09-12T17:08:39.419844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 3): ['PizzaTossing',\n",
       "  'shoot_bow',\n",
       "  'MoppingFloor',\n",
       "  'HammerThrow',\n",
       "  'Bowling'],\n",
       " (3, 6): ['PizzaTossing',\n",
       "  'Bowling',\n",
       "  'BreastStroke',\n",
       "  'BodyWeightSquats',\n",
       "  'MoppingFloor'],\n",
       " (6, 9): ['Nunchucks',\n",
       "  'ShavingBeard',\n",
       "  'CleanAndJerk',\n",
       "  'CricketBowling',\n",
       "  'PizzaTossing'],\n",
       " (9, 12): ['shoot_bow', 'PlayingFlute', 'PizzaTossing', 'JumpRope', 'Archery'],\n",
       " (12, 15): ['BlowDryHair',\n",
       "  'shoot_bow',\n",
       "  'ApplyLipstick',\n",
       "  'PizzaTossing',\n",
       "  'Skiing'],\n",
       " (15, 18): ['PizzaTossing', 'shoot_gun', 'BlowDryHair', 'PushUps', 'Skiing'],\n",
       " (18, 21): ['Skiing',\n",
       "  'PizzaTossing',\n",
       "  'ApplyLipstick',\n",
       "  'PlayingFlute',\n",
       "  'shoot_bow']}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions():\n",
    "    def meke_prediction_on_segment(frames):\n",
    "        frames = helpers.rescale_list(frames, SEQ_LENGTH)\n",
    "\n",
    "        inception_frame_features = extractor_model.extract_on_batch(frames)\n",
    "        inception_frame_features = np.expand_dims(inception_frame_features, axis=0)\n",
    "        \n",
    "        return model.model.predict_proba(inception_frame_features, verbose=0).ravel()\n",
    "    \n",
    "    def split_frames(frames):\n",
    "        def chunks(l, n):\n",
    "            \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "            for i in range(0, len(l), n):\n",
    "                yield l[i:i + n]\n",
    "        \n",
    "        n_frames = len(frames)\n",
    "        segment_length = FPS * SEGMENT_TIME\n",
    "        \n",
    "        for i, chunk in enumerate(chunks(frames, segment_length)):\n",
    "            if len(chunk) < SEQ_LENGTH:\n",
    "                continue\n",
    "            yield chunk, i * SEGMENT_TIME, (i + 1) * SEGMENT_TIME\n",
    "        \n",
    "    preds = {}\n",
    "    \n",
    "    for video in tqdm_notebook(get_videos(DATA_PATH), desc='Making predictions'):\n",
    "        video_rgb_frames_path = os.path.join(RGB_FRAMES_PATH, video.name)\n",
    "        frames = helpers.get_rgb_frames(video_rgb_frames_path)\n",
    "\n",
    "        if SEGMENT_TIME:\n",
    "            for segment, start_time, end_time in tqdm_notebook(split_frames(frames), leave=False):\n",
    "                preds[(video.path, start_time, end_time)] = meke_prediction_on_segment(segment)\n",
    "        else:\n",
    "            preds[video.path] = meke_prediction_on_segment(frames)\n",
    "        \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T15:41:41.247864Z",
     "start_time": "2017-09-12T15:41:40.659902Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for i, (input, target) in enumerate(val_loader):\n",
    "    target = target.cuda(async=True)\n",
    "    input_var = torch.autograd.Variable(input, volatile=True)\n",
    "    target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "    # compute output\n",
    "    output = model(input_var)\n",
    "    \n",
    "    y_pred.extend(output)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
