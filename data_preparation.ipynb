{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T05:29:51.664056Z",
     "start_time": "2017-09-14T05:29:51.658052Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from collections import namedtuple, defaultdict\n",
    "\n",
    "import helpers\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T05:30:42.627391Z",
     "start_time": "2017-09-14T05:30:42.612137Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPLIT_ID = 1\n",
    "\n",
    "DATASET_PATH = '/media/d/vsd/data/ucf101'\n",
    "DATA_PATH = os.path.join(DATASET_PATH, 'UCF-101')\n",
    "\n",
    "PREPROCESSED_PATH = '/media/e/vsd/data/ucf101_preprocessed'\n",
    "PREPROCESSED_SPLIT_PATH = os.path.join(PREPROCESSED_PATH, 'split_{0:02d}'.format(SPLIT_ID))\n",
    "\n",
    "FPS = 25\n",
    "WIDTH = 320\n",
    "HEIGHT = 240\n",
    "\n",
    "SKIP_EXIST = False\n",
    "\n",
    "FNULL = open(os.devnull, 'w')\n",
    "\n",
    "if not SKIP_EXIST:\n",
    "    shutil.rmtree(PREPROCESSED_SPLIT_PATH, ignore_errors=True)\n",
    "    \n",
    "helpers.ensure_path_exists(PREPROCESSED_SPLIT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T05:30:57.632882Z",
     "start_time": "2017-09-14T05:30:57.614705Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Video(namedtuple('VideoPath', ['class_', 'name', 'extension'])):\n",
    "    @classmethod\n",
    "    def parse_split_line(cls, line):\n",
    "        path, extension = os.path.splitext(line.strip())\n",
    "        class_, name = os.path.split(path)\n",
    "        \n",
    "        return cls(class_=class_, name=name, extension=extension)\n",
    "    \n",
    "    @property\n",
    "    def path(self):\n",
    "        return '{0.class_}/{0.name}{0.extension}'.format(self)\n",
    "    \n",
    "    @property\n",
    "    def path_no_ext(self):\n",
    "        return '{0.class_}/{0.name}'.format(self)   \n",
    "    \n",
    "    \n",
    "def get_split_videos(train_or_test):\n",
    "    assert train_or_test in {'train', 'test'}\n",
    "    path = os.path.join(DATASET_PATH, 'ucfTrainTestlist', '{0}list{1:02d}.txt'.format(train_or_test, SPLIT_ID))\n",
    "    \n",
    "    with open(path) as f:\n",
    "        return [Video.parse_split_line(l.strip().split()[0]) for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для разбиения sp1 генерим RGB с помощью FFMPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T05:30:59.313665Z",
     "start_time": "2017-09-14T05:30:59.264058Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_rgb(train_or_test, n_jobs=8):\n",
    "    dst_path = os.path.join(PREPROCESSED_SPLIT_PATH, train_or_test)\n",
    "    rgb_path = os.path.join(dst_path, 'rgb')\n",
    "    \n",
    "    videos = get_split_videos(train_or_test)\n",
    "    \n",
    "    # prepare dirs\n",
    "    classes = {video.class_ for video in videos}\n",
    "    [helpers.ensure_path_exists(os.path.join(rgb_path, class_)) for class_ in classes]\n",
    "    \n",
    "    def prepare_tasks():\n",
    "        for video in videos:\n",
    "            src_video_path = os.path.join(DATA_PATH, video.path)\n",
    "            dst_video_path = os.path.join(rgb_path, video.path_no_ext)\n",
    "        \n",
    "            if SKIP_EXIST and os.path.exists(dst_video_path)\\\n",
    "                and os.path.isdir(dst_video_path) and os.listdir(dst_video_path):\n",
    "                    continue\n",
    "                    \n",
    "            helpers.ensure_path_exists(dst_video_path)\n",
    "            dst_frames_template_path = os.path.join(dst_video_path, '%04d.jpg')\n",
    "            \n",
    "            yield src_video_path, dst_frames_template_path, FPS, WIDTH, HEIGHT\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    def do_work(pool):\n",
    "        with tqdm_notebook(desc='[{}] RGB Generation'.format(train_or_test), total=len(videos)) as pbar:\n",
    "            for is_ok, src_video_path in pool(helpers.extract_rgb_frames, prepare_tasks()):\n",
    "                pbar.update(1)\n",
    "                \n",
    "                if not is_ok:\n",
    "                    errors.append(src_video_path)\n",
    "                    \n",
    "    def dummy_pool(func, tasks):\n",
    "        for task in tasks:\n",
    "            yield func(task)\n",
    "\n",
    "    \n",
    "    if n_jobs > 1:\n",
    "        with multiprocessing.Pool(n_jobs) as pool:\n",
    "            do_work(pool.imap_unordered)\n",
    "    else:\n",
    "        do_work(dummy_pool)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T05:39:13.436996Z",
     "start_time": "2017-09-14T05:31:01.670600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d45a85e8204570a7f7adcff2d2402f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6015542f674d048116b401c0a6de6d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_errors = generate_rgb('train', 6)\n",
    "test_errors = generate_rgb('test', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [уже не нужно] Будем генерить оптический поток с помощью flownet 2.0 из контейнера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T17:12:04.238731Z",
     "start_time": "2017-09-06T17:12:04.163116Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_flow_tasks(train_or_test):\n",
    "    _1st_images, _2nd_images, flow_images = [], [], []\n",
    "    \n",
    "    n_skipped = 0\n",
    "    \n",
    "    rgb_path = os.path.join(PREPROCESSED_SPLIT_PATH, train_or_test, 'rgb')\n",
    "    flow_path = os.path.join(PREPROCESSED_SPLIT_PATH, train_or_test, 'flow')\n",
    "    helpers.ensure_path_exists(flow_path)\n",
    "    \n",
    "    path_prefix_len = len(PREPROCESSED_SPLIT_PATH) + 1\n",
    "    \n",
    "    for class_ in tqdm_notebook(os.listdir(rgb_path), desc='[{}] Flow Task Generation'.format(train_or_test)):\n",
    "        src_class_path = os.path.join(rgb_path, class_)\n",
    "        dst_class_path = os.path.join(flow_path, class_)\n",
    "        helpers.ensure_path_exists(dst_class_path)\n",
    "        \n",
    "        for video_name in os.listdir(src_class_path):\n",
    "            src_video_path = os.path.join(src_class_path, video_name)\n",
    "            dst_video_path = os.path.join(dst_class_path, video_name)\n",
    "            helpers.ensure_path_exists(dst_video_path)            \n",
    "            \n",
    "            frame_names = list(sorted(os.listdir(src_video_path)))\n",
    "            \n",
    "            for _1st_frame, _2nd_frame in zip(frame_names, frame_names[1:]):\n",
    "                _1st_frame_path = os.path.join(src_video_path, _1st_frame)\n",
    "                _2nd_frame_path = os.path.join(src_video_path, _2nd_frame)\n",
    "                \n",
    "                flow_frame_path = os.path.join(dst_video_path, _1st_frame.replace('.jpg', '.flo'))\n",
    "                \n",
    "                if SKIP_EXIST and os.path.exists(flow_frame_path):\n",
    "                    n_skipped += 1\n",
    "                    continue\n",
    "                    \n",
    "                _1st_frame_path = _1st_frame_path[path_prefix_len:]\n",
    "                _2nd_frame_path = _2nd_frame_path[path_prefix_len:]\n",
    "                flow_frame_path = flow_frame_path[path_prefix_len:]\n",
    "                \n",
    "                _1st_images.append(_1st_frame_path)\n",
    "                _2nd_images.append(_2nd_frame_path)\n",
    "                flow_images.append(flow_frame_path)               \n",
    "    \n",
    "    tasks_dir = os.path.join(PREPROCESSED_SPLIT_PATH, 'flow_tasks', train_or_test)\n",
    "    helpers.ensure_path_exists(tasks_dir)\n",
    "    \n",
    "    path_list_name = [\n",
    "        [_1st_images, '1st'],\n",
    "        [_2nd_images, '2nd'],\n",
    "        [flow_images, 'flow']\n",
    "    ]\n",
    "        \n",
    "    for path_list, name in path_list_name:\n",
    "        with open(os.path.join(tasks_dir, '{}.txt'.format(name)), 'w+') as f:\n",
    "            for path in path_list:\n",
    "                f.write(path + '\\n')\n",
    "            f.write(path_list[-1])\n",
    "                \n",
    "    print(train_or_test, 'skipped', n_skipped, 'frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-07T00:18:05.802105Z",
     "start_time": "2017-09-07T00:18:05.612089Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate_flow_tasks('test')\n",
    "generate_flow_tasks('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# сгенерим .sh для запуска генерации потока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T17:24:29.534031Z",
     "start_time": "2017-09-06T17:24:29.518848Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_sh(train_or_test):\n",
    "    run_file_path = 'run-network.sh'\n",
    "\n",
    "    tasks_dir = os.path.join(PREPROCESSED_SPLIT_PATH, 'flow_tasks', train_or_test)\n",
    "\n",
    "    base_command = 'sh {run_file} -n FlowNet2-s {{img1}} {{img2}} {{flow}}'.format(run_file=run_file_path)\n",
    "\n",
    "    with open(os.path.join(tasks_dir, 'gen_flow.sh'), 'w+') as f:\n",
    "        img1_list_path = os.path.join('flow_tasks', train_or_test, '1st.txt')\n",
    "        img2_list_path = os.path.join('flow_tasks', train_or_test, '2nd.txt')\n",
    "        flow_list_path = os.path.join('flow_tasks', train_or_test, 'flow.txt')\n",
    "\n",
    "        f.write(base_command.format(img1=img1_list_path, img2=img2_list_path, flow=flow_list_path) + '\\n')\n",
    "            \n",
    "gen_sh('test')\n",
    "gen_sh('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение списка файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T05:40:39.484440Z",
     "start_time": "2017-09-14T05:40:38.209239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes: 101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb2ab02a4d048e585ce0c6c15b5de3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499eb22d3de043d0b778f882fbff2320"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_class_index(split_id):\n",
    "    classes = {v.class_ for v in get_split_videos('train')}\n",
    "    return {class_: idx for idx, class_ in enumerate(sorted(classes))}\n",
    "\n",
    "def generate_file_list(train_or_test, flow_or_rgb, class_index):\n",
    "    data_path = os.path.join(PREPROCESSED_SPLIT_PATH, train_or_test, flow_or_rgb)\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    for class_ in tqdm_notebook(os.listdir(data_path), desc=train_or_test):\n",
    "        class_path = os.path.join(data_path, class_)\n",
    "        \n",
    "        for video in os.listdir(class_path):\n",
    "            video_path = os.path.join(class_path, video)\n",
    "            \n",
    "            rows.append({\n",
    "                'class': class_index[class_],\n",
    "                'path': video_path,\n",
    "                'n_frames': len(os.listdir(video_path))\n",
    "            })\n",
    "            \n",
    "    file_lists_dir = os.path.join(PREPROCESSED_SPLIT_PATH, 'file_lists')\n",
    "    helpers.ensure_path_exists(file_lists_dir)\n",
    "    \n",
    "    file_list_path = os.path.join(file_lists_dir, '{}_{}.txt'.format(train_or_test, flow_or_rgb))\n",
    "    pd.DataFrame(rows)[['path', 'n_frames', 'class']].to_csv(file_list_path, index=False, header=False, sep=' ')\n",
    "    \n",
    "class_index = create_class_index(SPLIT_ID)\n",
    "\n",
    "print('n_classes:', len(class_index))\n",
    "\n",
    "generate_file_list('train', 'rgb', class_index)\n",
    "generate_file_list('test', 'rgb', class_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
